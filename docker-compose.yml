version: '3.8'

services:
  llm-service:
    build: .
    container_name: llm_api
    ports:
      - "8000:8000"
    environment:
      - API_KEY=${API_KEY:-mysecurekey123}
      - MODEL_NAME=gpt2-medium
      - HF_HOME=/home/appuser/huggingface
    volumes:
      - hf_cache:/home/appuser/huggingface
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    restart: unless-stopped

volumes:
  hf_cache: